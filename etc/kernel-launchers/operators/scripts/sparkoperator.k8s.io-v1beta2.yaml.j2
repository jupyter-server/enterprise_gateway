apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: {{ kernel_resource_name }}
spec:
  restartPolicy:
    type: Never
  type: Python
  pythonVersion: "3"
  sparkVersion: 2.4.5
  image: {{ kernel_image }}
  mainApplicationFile: "local:///usr/local/bin/kernel-launchers/python/scripts/launch_ipykernel.py"
  arguments:
    - "--kernel-id"
    - "{{ kernel_id }}"
    - "--spark-context-initialization-mode"
    - "{{ spark_context_initialization_mode }}"
    - "--response-address"
    - "{{ eg_response_address }}"
    - "--port-range"
    - "{{ eg_port_range }}"
    - "--public-key"
    - "{{ eg_public_key }}"
  driver:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "false"
    env:
# Add any custom envs here that aren't already configured for the kernel's environment
# Note: For envs to flow to the pods, the webhook server must be enabled during deployment
# e.g., helm install my-release spark-operator/spark-operator --namespace spark-operator --set webhook.enable=true
#    - name: MY_DRIVER_ENV
#      value: "my_driver_value"
    serviceAccount: "{{ kernel_service_account_name }}"
    labels:
      kernel_id: "{{ kernel_id }}"
      app: enterprise-gateway
      component: kernel
    cores: 1
    coreLimit: 1000m
    memory: 1g
  executor:
    env:
# Add any custom envs here that aren't already configured for the kernel's environment
# Note: For envs to flow to the pods, the webhook server must be enabled during deployment
# e.g., helm install my-release spark-operator/spark-operator --namespace spark-operator --set webhook.enable=true
#    - name: MY_EXECUTOR_ENV
#      value: "my_executor_value"
    labels:
      kernel_id: "{{ kernel_id }}"
      app: enterprise-gateway
      component: worker
    image: {{ kernel_executor_image }}
    instances: 2
    cores: 1
    coreLimit: 1000m
    memory: 1g
{% if kernel_sparkapp_config_map %}
  sparkConfigMap: {{ kernel_sparkapp_config_map }}
{% endif %}
